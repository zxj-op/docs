---
openapi: api-reference/qwen/openapi.json POST /iu/chat/completions
title: Qwen
description: "Generate chat completions using Qwen ILM model with image inputs."
---

This endpoint allows you to generate chat completions with image inputs using Qwen ILM model.

## Supported Models

All models require the `qwen:` prefix when used in the `model` parameter (e.g., `qwen:qwen3-vl-plus`).

### Qwen 3 VL Plus (Premium - Tiered Pricing)

| Model | Input Price | Output Price |
|-------|------------|--------------|
| **qwen3-vl-plus** | \$0.00021/1K (≤32K), \$0.00031/1K (32K-128K), \$0.00063/1K (128K-256K) | \$0.00168/1K (≤32K), \$0.00252/1K (32K-128K), \$0.00503/1K (128K-256K) |
| **qwen3-vl-plus-2025-12-19** | \$0.00021/1K (≤32K), \$0.00031/1K (32K-128K), \$0.00063/1K (128K-256K) | \$0.00168/1K (≤32K), \$0.00252/1K (32K-128K), \$0.00503/1K (128K-256K) |
| **qwen3-vl-plus-2025-09-23** | \$0.00021/1K (≤32K), \$0.00031/1K (32K-128K), \$0.00063/1K (128K-256K) | \$0.00168/1K (≤32K), \$0.00252/1K (32K-128K), \$0.00503/1K (128K-256K) |

### Qwen 3 VL Flash (Cost-Effective - Tiered Pricing)

| Model | Input Price | Output Price |
|-------|------------|--------------|
| **qwen3-vl-flash** | \$0.000052/1K (≤32K), \$0.000079/1K (32K-128K), \$0.000126/1K (128K-256K) | \$0.00042/1K (≤32K), \$0.00063/1K (32K-128K), \$0.00101/1K (128K-256K) |
| **qwen3-vl-flash-2025-10-15** | \$0.000052/1K (≤32K), \$0.000079/1K (32K-128K), \$0.000126/1K (128K-256K) | \$0.00042/1K (≤32K), \$0.00063/1K (32K-128K), \$0.00101/1K (128K-256K) |

### Qwen VL Max (Legacy)

| Model | Input Price | Output Price |
|-------|------------|--------------|
| **qwen-vl-max** | \$0.00084/1K tokens | \$0.00335/1K tokens |
| **qwen-vl-max-latest** | \$0.00084/1K tokens | \$0.00335/1K tokens |
| **qwen-vl-max-2025-08-13** | \$0.00084/1K tokens | \$0.00335/1K tokens |
| **qwen-vl-max-2025-04-08** | \$0.00084/1K tokens | \$0.00335/1K tokens |

### Qwen VL Plus (Legacy)

| Model | Input Price | Output Price |
|-------|------------|--------------|
| **qwen-vl-plus** | \$0.00022/1K tokens | \$0.00066/1K tokens |
| **qwen-vl-plus-latest** | \$0.00022/1K tokens | \$0.00066/1K tokens |
| **qwen-vl-plus-2025-08-15** | \$0.00022/1K tokens | \$0.00066/1K tokens |
| **qwen-vl-plus-2025-05-07** | \$0.00022/1K tokens | \$0.00066/1K tokens |
| **qwen-vl-plus-2025-01-25** | \$0.00022/1K tokens | \$0.00066/1K tokens |

<Note>
**Pricing Notes:**
- All prices are per 1,000 tokens and converted from CNY at exchange rate of 7.0
- Qwen 3 VL models support tiered pricing: ≤32K, 32K-128K, 128K-256K token ranges
- Legacy models (Qwen VL Max/Plus) use flat-rate pricing
- Remember to include the `qwen:` prefix: `"model": "qwen:qwen3-vl-plus"`
</Note>

### Request Body

| Parameter | Type | Required | Default | Description |
|-----------|------|----------|---------|-------------|
| model | string | Yes | - | The model to use (e.g., `qwen:qwen3-vl-plus`) |
| messages | array | Yes | - | Array of message objects. Each message contains:<br/>- `role`: Role type, values: `system`, `user`<br/>- `content`: Message content, can be a string or array. Array items can contain:<br/>  - `image`: Image URL or base64 encoded image<br/>  - `text`: Text content |
| temperature | number | No | 0.7 | Controls randomness: 0.0-2.0, higher = more random |
| max_tokens | integer | No | 1024 | Maximum number of tokens to generate |
| top_p | number | No | 0.9 | Nucleus sampling: 0.0-1.0, consider tokens with top_p probability mass |
| frequency_penalty | number | No | 0.0 | Reduces repetition of frequent tokens: -2.0 to 2.0 |
| presence_penalty | number | No | 0.0 | Increases likelihood of new topics: -2.0 to 2.0 |
| n | integer | No | 1 | Number of completions to generate |
| stream | boolean | No | false | Whether to stream the response |
| stop | string \| array \| null | No | null | Stop sequences. Can be a string, array of strings, or null |
| extra_body | object | No | - | Additional body parameters. Contains:<br/>- `metadata`: Metadata object<br/>  - `enable_thinking`: Boolean to enable thinking mode<br/>  - `thinking_budget`: Integer value for thinking budget<br/>  - `response_format`: Response format configuration<br/>    - `type`: Format type (`json_schema`)<br/>    - `json_schema`: JSON schema object<br/>      - `name`: Schema name<br/>      - `schema`: JSON schema definition |

### Code Example

<CodeGroup>



```python Python
from openai import OpenAI

client = OpenAI(
    api_key="sk-mai-this_a_test_string_please_use_your_generated_key_during_testing",
    base_url="https://mavi-backend.memories.ai/serve/api/v2/iu"
)

resp = client.chat.completions.create(
    model="qwen:qwen3-vl-plus",
    messages=[
        {"role": "system", "content": "You are a multimodal assistant. Keep your answers concise."},
        {
            "role": "user",
            "content": [
                {
                    "image": "https://storage.googleapis.com/memories-test-data/gun5.png"  # url or base64
                },
                {"text": "What is the content of this image?"}
            ]
        }
    ],
    temperature=0.7,  # Controls randomness: 0.0-2.0, higher = more random
    max_tokens=1024,  # Maximum number of tokens to generate
    top_p=0.9,  # Nucleus sampling: 0.0-1.0, consider tokens with top_p probability mass
    frequency_penalty=0.0,  # -2.0 to 2.0, reduces repetition of frequent tokens
    presence_penalty=0.0,  # -2.0 to 2.0, increases likelihood of new topics
    n=1,  # Number of completions to generate
    stream=False,  # Whether to stream the response
    stop=None,  # Stop sequences (list of strings)
    extra_body={
        "metadata": {
            "enable_thinking": True,
            "thinking_budget": 1024,
            "response_format": {
                "type": "json_schema",
                "json_schema": {
                    "name": "answer",
                    "schema": {
                        "type": "object",
                        "properties": {
                            "result": {"type": "string"}
                        },
                        "required": ["result"]
                    }
                }
            }
        }
    }
)
print(resp)
```

</CodeGroup>

### Response

Returns the chat completion response with structured output.

<ResponseExample>
```json
{
  "id": "6612267a-d08f-9ea0-a254-7bcea6339f49",
  "object": "completion",
  "model": "qwen3-vl-plus",
  "created_at": 1767094289,
  "status": "completed",
  "choices": [
    {
      "text": "This image is from the game Half-Life 2, showing a game scene from a first-person perspective.\n\nIn the scene, the player holds a \"Gravity Gun\" in each hand, aiming at the wall ahead. A yellow \"Mandatory Reminder\" sign hangs on the wall, printed with the U.S. national emblem pattern and inscribed with \"AMENDMENT 35\" (35th Amendment), with text below reading: \"No person shall be found with fewer than thirteen times their own body weight of federally provisioned munitions.\" - This is clearly a fictional absurd law within the game.\n\nThe bottom left corner of the screen shows the player's \"HEALTH\" and \"SUIT\" both at 100. The bottom right corner displays ammunition information \"IDC ANYMORE AMMO\", suggesting ample or infinite ammunition.\n\nThe entire scene is full of dark humor and dystopian style, one of the iconic scenes from Half-Life 2, often used by players as memes or screenshots for sharing.",
      "index": 0
    }
  ],
  "usage": {
    "input_tokens": 235,
    "output_tokens": 229,
    "total_tokens": 464
  },
  "meta": {
    "provider": "qwen",
    "provider_model": "qwen3-vl-plus"
  }
}
```
</ResponseExample>

### Response Parameters

| Parameter | Type | Description |
|-----------|------|-------------|
| id | string | Unique identifier for the completion |
| object | string | Object type, always "completion" |
| model | string | The model used for the completion |
| created_at | integer | Unix timestamp of when the completion was created |
| status | string | Status of the completion (e.g., "completed") |
| choices | array | Array of completion choices |
| choices[].text | string | Text content of the completion |
| choices[].index | integer | Index of the choice in the choices array |
| usage | object | Token usage information |
| usage.input_tokens | integer | Number of input tokens used |
| usage.output_tokens | integer | Number of output tokens generated |
| usage.total_tokens | integer | Total number of tokens used |
| meta | object | Metadata about the completion |
| meta.provider | string | Provider name (e.g., "qwen") |
| meta.provider_model | string | Provider-specific model name |

